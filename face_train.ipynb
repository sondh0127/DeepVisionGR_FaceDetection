{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "from keras_ssd_loss import SSDLoss\n",
    "\n",
    "from ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\n",
    "\n",
    "\n",
    "from mn_model import mn_model\n",
    "from face_generator import BatchGenerator\n",
    "from config import path\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # choose gpu\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Set the model configuration parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "img_channels = 3\n",
    "\n",
    "n_classes = 2\n",
    "class_names = [\"background\", \"face\"]\n",
    "\n",
    "scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]  # anchorboxes for coco dataset\n",
    "aspect_ratios = [\n",
    "    [0.5, 1.0, 2.0],\n",
    "    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "    [0.5, 1.0, 2.0],\n",
    "    [0.5, 1.0, 2.0],\n",
    "]  # The anchor box aspect ratios used in the original SSD300\n",
    "two_boxes_for_ar1 = True\n",
    "# Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "limit_boxes = True\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "# The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "coords = \"centroids\"\n",
    "# Whether the box coordinates to be used as targets for the model should be in the 'centroids' or 'minmax' format, see documentation\n",
    "normalize_coords = True\n",
    "\n",
    "det_model_path = \"./models/\"\n",
    "train_data = \"wider_train_v1.npy\"\n",
    "test_data = \"wider_val_v1.npy\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Build or load the model\n",
    "### 2.1 Create a new model and load trained Mobinet weights"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1: Build the Keras model.\n",
    "K.clear_session()  # Clear previous models from memory.\n",
    "model, model_layer, img_input, predictor_sizes = mn_model(\n",
    "    image_size=(img_height, img_width, img_channels),\n",
    "    n_classes=n_classes,\n",
    "    min_scale=None,\n",
    "    max_scale=None,\n",
    "    scales=scales,\n",
    "    aspect_ratios_global=None,\n",
    "    aspect_ratios_per_layer=aspect_ratios,\n",
    "    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "    limit_boxes=limit_boxes,\n",
    "    variances=variances,\n",
    "    coords=coords,\n",
    "    normalize_coords=normalize_coords,\n",
    ")\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "print(\"Freezing classification layers\")\n",
    "# Freeze layers\n",
    "for layer_key in model_layer:\n",
    "    if \"detection\" not in layer_key:\n",
    "        # prefix detection to freeze layers which does not have detection\n",
    "        model_layer[layer_key].trainable = False\n",
    "print(colored(\"classification layers freezed\", \"green\"))\n",
    "\n",
    "# for layer in model.layers:\n",
    "#   print (colored(layer.name, 'blue'))\n",
    "#   print (colored(layer.trainable, 'green'))\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "print(\"Loading classification weights\")\n",
    "# classification_model = \"./base_models/mobilenet_1_0_224_tf.h5\"\n",
    "classification_model = \"./models/ssd_mobilenet_face_epoch_07_loss5.8451.h5\"\n",
    "model.load_weights(classification_model, by_name=True)\n",
    "print(colored((\"Classification weights %s loaded\" % classification_model), \"green\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "#Adam\n",
    "base_lr = 0.001\n",
    "adam = Adam(lr=base_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-6, decay = 0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=2, n_neg_min=0, alpha=1.0, beta = 1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "\n",
    "print(predictor_sizes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.2 Load a previously created model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Load a previously model\n",
    "# model_path = './models/ssd_mobilenet_face_epoch_01_loss6.0995.h5'\n",
    "\n",
    "# # We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "# ssd_loss = SSDLoss(neg_pos_ratio=2, alpha=1.0)\n",
    "\n",
    "# K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "# model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "#                                                'L2Normalization': L2Normalization,\n",
    "#                                                'compute_loss': ssd_loss.compute_loss})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Set up the data generators for the training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "# Create ground truth box encoder\n",
    "ssd_box_encoder = SSDBoxEncoder(\n",
    "    img_height=img_height,\n",
    "    img_width=img_width,\n",
    "    n_classes=n_classes,\n",
    "    predictor_sizes=predictor_sizes,\n",
    "    min_scale=None,\n",
    "    max_scale=None,\n",
    "    scales=scales,\n",
    "    aspect_ratios_global=None,\n",
    "    aspect_ratios_per_layer=aspect_ratios,\n",
    "    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "    limit_boxes=limit_boxes,\n",
    "    variances=variances,\n",
    "    pos_iou_threshold=0.5,\n",
    "    neg_iou_threshold=0.2,\n",
    "    coords=coords,\n",
    "    normalize_coords=normalize_coords,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset = BatchGenerator(\n",
    "    images_path=train_data,\n",
    "    include_classes=\"all\",\n",
    "    box_output_format=[\"class_id\", \"xmin\", \"xmax\", \"ymin\", \"ymax\"],\n",
    ")\n",
    "\n",
    "print(\"TRAINING DATA\")\n",
    "\n",
    "train_dataset.parse_xml(\n",
    "    annotations_path=train_data,\n",
    "    image_set_path=path.DRIVE_BASE_PATH,\n",
    "    image_set=\"None\",\n",
    "    classes=class_names,\n",
    "    exclude_truncated=False,\n",
    "    exclude_difficult=False,\n",
    "    ret=False,\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "train_generator = train_dataset.generate(\n",
    "    batch_size=batch_size,\n",
    "    train=True,\n",
    "    ssd_box_encoder=ssd_box_encoder,\n",
    "    equalize=True,\n",
    "    brightness=(0.5, 2, 0.5),\n",
    "    flip=0.5,\n",
    "    translate=((0, 20), (0, 30), 0.5),\n",
    "    scale=(0.75, 1.2, 0.5),\n",
    "    crop=False,\n",
    "    # random_crop = (img_height,img_width,1,3),\n",
    "    random_crop=False,\n",
    "    resize=(img_height, img_width),\n",
    "    # resize=False,\n",
    "    gray=False,\n",
    "    limit_boxes=True,\n",
    "    include_thresh=0.4,\n",
    "    diagnostics=False,\n",
    ")\n",
    "\n",
    "n_train_samples = train_dataset.get_n_samples()\n",
    "\n",
    "print(\"Total number of training samples = {}\".format(n_train_samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"VALIDATION DATA\")\n",
    "\n",
    "val_dataset = BatchGenerator(\n",
    "    images_path=test_data,\n",
    "    include_classes=\"all\",\n",
    "    box_output_format=[\"class_id\", \"xmin\", \"xmax\", \"ymin\", \"ymax\"],\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset.parse_xml(\n",
    "    annotations_path=test_data,\n",
    "    image_set_path=path.DRIVE_BASE_PATH,\n",
    "    image_set=\"None\",\n",
    "    classes=class_names,\n",
    "    exclude_truncated=False,\n",
    "    exclude_difficult=False,\n",
    "    ret=False,\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_dataset.generate(\n",
    "    batch_size=batch_size,\n",
    "    train=True,\n",
    "    ssd_box_encoder=ssd_box_encoder,\n",
    "    equalize=False,\n",
    "    brightness=False,\n",
    "    flip=False,\n",
    "    translate=False,\n",
    "    scale=False,\n",
    "    crop=False,\n",
    "    # random_crop = (img_height,img_width,1,3),\n",
    "    random_crop=False,\n",
    "    resize=(img_height, img_width),\n",
    "    # resize=False,\n",
    "    gray=False,\n",
    "    limit_boxes=True,\n",
    "    include_thresh=0.4,\n",
    "    diagnostics=False,\n",
    ")\n",
    "\n",
    "n_val_samples = val_dataset.get_n_samples()\n",
    "\n",
    "print(\"Total number of validation samples = {}\".format(n_val_samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Set the remaining training parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.95)\n",
    "        print(\"lr changed to {}\".format(lr * 0.95))\n",
    "    else:\n",
    "        print(\"lr remains {}\".format(K.get_value(model.optimizer.lr)))\n",
    "\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "\n",
    "# Define a learning rate schedule.\n",
    "lr_schedule = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Define model callbacks.\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=100)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    det_model_path + \"ssd_mobilenet_face_epoch_{epoch:02d}_loss{val_loss:.4f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    period=1,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now start the training\n",
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "initial_epoch = 0\n",
    "final_epoch = 15\n",
    "steps_per_epoch = ceil(n_train_samples / batch_size) * 2\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=final_epoch,\n",
    "    callbacks=[model_checkpoint, lr_schedule, early_stopping],\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=ceil(n_val_samples / batch_size),\n",
    "    initial_epoch=initial_epoch,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Make predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_path = \"./models/\"\n",
    "# model_name = \"ssd_mobilenet_face_epoch_25_loss0.0916.h5\"\n",
    "model_name = 'ssd_mobilenet_face_epoch_30_loss0.0767.h5'\n",
    "\n",
    "model.load_weights(model_path + model_name, by_name=True)\n",
    "\n",
    "print(colored(\"weights %s loaded\" % (model_path + model_name), \"green\"))\n",
    "\n",
    "\n",
    "def save_bb(save_path, filename, results, prediction=True):\n",
    "\n",
    "    # print filename\n",
    "\n",
    "    img = image.load_img(filename, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    filename = filename.split(\"/\")[-1]\n",
    "\n",
    "    if not prediction:\n",
    "        filename = filename[:-4] + \"_gt\" + \".jpg\"\n",
    "\n",
    "    # fig,current_axis = plt.subplots(1)\n",
    "    current_axis = plt.gca()\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 25)).tolist()\n",
    "    color_code = min(len(results), 16)\n",
    "    print(colored(\"total number of bbs: %d\" % len(results), \"yellow\"))\n",
    "    det_conf = None\n",
    "    for result in results:\n",
    "        # Parse the outputs.\n",
    "\n",
    "        if prediction:\n",
    "            det_label = result[0]\n",
    "            det_conf = result[1]\n",
    "            det_xmin = result[2]\n",
    "            det_xmax = result[3]\n",
    "            det_ymin = result[4]\n",
    "            det_ymax = result[5]\n",
    "        else:\n",
    "            det_label = result[0]\n",
    "            det_xmin = result[1]\n",
    "            det_xmax = result[2]\n",
    "            det_ymin = result[3]\n",
    "            det_ymax = result[4]\n",
    "\n",
    "        xmin = int(det_xmin)\n",
    "        ymin = int(det_ymin)\n",
    "        xmax = int(det_xmax)\n",
    "        ymax = int(det_ymax)\n",
    "\n",
    "        if prediction:\n",
    "            score = det_conf\n",
    "\n",
    "        plt.imshow(img / 255.0)\n",
    "\n",
    "        label = int(int(det_label))\n",
    "        label_name = class_names[label]\n",
    "        # print label_name\n",
    "        # print label\n",
    "\n",
    "        if prediction:\n",
    "            display_txt = \"{:0.2f}\".format(score)\n",
    "        else:\n",
    "            display_txt = \"{}\".format(label_name)\n",
    "\n",
    "        # print (xmin, ymin, ymin, ymax)\n",
    "        box_coords = (xmin, ymin), (xmax - xmin), (ymax - ymin)\n",
    "        color_code = color_code - 1\n",
    "        color = colors[color_code]\n",
    "        current_axis.add_patch(\n",
    "            plt.Rectangle(*box_coords, fill=False, edgecolor=color, linewidth=2)\n",
    "        )\n",
    "        current_axis.text(\n",
    "            xmin, ymin, display_txt, bbox={\"facecolor\": color, \"alpha\": 0.2}\n",
    "        )\n",
    "\n",
    "    current_axis.axes.get_yaxis().set_visible(False)\n",
    "    current_axis.axes.get_xaxis().set_visible(False)\n",
    "    plt.savefig(save_path + filename, bbox_inches=\"tight\")\n",
    "\n",
    "    print(\"saved\", save_path + filename)\n",
    "\n",
    "    plt.clf()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 1: Set the generator for the predictions.\n",
    "eval_dir = '/content/Object-Detection-Metrics/face/'\n",
    "test_size = 100\n",
    "test_generator = val_dataset.generate(\n",
    "    batch_size=test_size,\n",
    "    train=False,\n",
    "    ssd_box_encoder=ssd_box_encoder,\n",
    "    equalize=False,\n",
    "    brightness=False,\n",
    "    flip=False,\n",
    "    translate=False,\n",
    "    scale=False,\n",
    "    crop=False,\n",
    "    #random_crop = (img_height,img_width,1,3), \n",
    "    random_crop=False, \n",
    "    resize=(img_height, img_width), \n",
    "    #resize=False,\n",
    "    gray=False,\n",
    "    limit_boxes=True,\n",
    "    include_thresh=0.4,\n",
    "    diagnostics=False\n",
    ")\n",
    "\n",
    "print(colored(\"Done.\", \"green\"))\n",
    "\n",
    "print(colored(\"Now predicting...\", \"yellow\"))\n",
    "\n",
    "_CONF = 0.40 \n",
    "_IOU = 0.1\n",
    "\n",
    "for i in range(test_size):\n",
    "    X, y, filenames = next(test_generator)\n",
    "    y_pred = model.predict(X)\n",
    "    # 4: Decode the raw predictions in `y_pred`.\n",
    "    y_pred_decoded = decode_y2(\n",
    "        y_pred,\n",
    "        confidence_thresh=_CONF,\n",
    "        iou_threshold=_IOU,\n",
    "        top_k=\"all\",\n",
    "        normalize_coords=normalize_coords,\n",
    "        input_coords=coords,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "    )\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "\n",
    "    save_bb(\"./output_test/\", filenames[i], y_pred_decoded[i])\n",
    "    save_bb(\"./output_test/\", filenames[i], y[i], prediction=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}