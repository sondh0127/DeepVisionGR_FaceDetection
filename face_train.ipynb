{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T14:33:21.367021Z",
     "start_time": "2018-03-09T22:33:12.637484+08:00"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 1;\n",
       "            var nbb_formatted_code = \"%load_ext nb_black\\n%load_ext lab_black\\nimport warnings\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\nfrom keras.optimizers import Adam\\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\\nfrom keras.callbacks import Callback\\nfrom keras import backend as K\\nfrom keras.models import load_model\\nfrom keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\\nfrom keras_layers.keras_layer_L2Normalization import L2Normalization\\nfrom math import ceil\\nimport numpy as np\\nfrom termcolor import colored\\nfrom keras_loss_function.keras_ssd_loss import SSDLoss\\n\\n# from ssd_encoder_decoder.ssd_input_encoder import SSDInputEncoder\\n# from ssd_encoder_decoder.ssd_output_decoder import (\\n#     decode_detections,\\n#     decode_detections_fast,\\n# )\\n\\nfrom ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\\n\\n\\nfrom mn_model import mn_model\\nfrom face_generator import BatchGenerator\\nfrom config import path\\nimport os\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"0\\\"  # choose gpu\\n%matplotlib inline\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%load_ext lab_black\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from termcolor import colored\n",
    "from keras_ssd_loss import SSDLoss\n",
    "\n",
    "from ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\n",
    "\n",
    "\n",
    "from mn_model import mn_model\n",
    "from face_generator import BatchGenerator\n",
    "from config import path\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # choose gpu\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1. Set the model configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T14:33:21.378011Z",
     "start_time": "2018-03-09T22:33:21.368987+08:00"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 2;\n",
       "            var nbb_formatted_code = \"img_height = 512\\nimg_width = 512\\nimg_channels = 3\\n\\nn_classes = 2\\nclass_names = [\\\"background\\\", \\\"face\\\"]\\n\\nscales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]  # anchorboxes for coco dataset\\naspect_ratios = [\\n    [0.5, 1.0, 2.0],\\n    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\\n    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\\n    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\\n    [0.5, 1.0, 2.0],\\n    [0.5, 1.0, 2.0],\\n]  # The anchor box aspect ratios used in the original SSD300\\ntwo_boxes_for_ar1 = True\\n# Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\\nlimit_boxes = True\\nvariances = [0.1, 0.1, 0.2, 0.2]\\n# The variances by which the encoded target coordinates are scaled as in the original implementation\\ncoords = \\\"centroids\\\"\\n# Whether the box coordinates to be used as targets for the model should be in the 'centroids' or 'minmax' format, see documentation\\nnormalize_coords = True\\n\\ndet_model_path = \\\"./models/\\\"\\ntrain_data = \\\"wider_train_v1.npy\\\"\\ntest_data = \\\"wider_val_v1.npy\\\"\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_height = 512\n",
    "img_width = 512\n",
    "img_channels = 3\n",
    "\n",
    "n_classes = 2\n",
    "class_names = [\"background\", \"face\"]\n",
    "\n",
    "scales = [0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05]  # anchorboxes for coco dataset\n",
    "aspect_ratios = [\n",
    "    [0.5, 1.0, 2.0],\n",
    "    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "    [1.0 / 3.0, 0.5, 1.0, 2.0, 3.0],\n",
    "    [0.5, 1.0, 2.0],\n",
    "    [0.5, 1.0, 2.0],\n",
    "]  # The anchor box aspect ratios used in the original SSD300\n",
    "two_boxes_for_ar1 = True\n",
    "# Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "limit_boxes = True\n",
    "variances = [0.1, 0.1, 0.2, 0.2]\n",
    "# The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "coords = \"centroids\"\n",
    "# Whether the box coordinates to be used as targets for the model should be in the 'centroids' or 'minmax' format, see documentation\n",
    "normalize_coords = True\n",
    "\n",
    "det_model_path = \"./models/\"\n",
    "train_data = \"wider_train_v1.npy\"\n",
    "test_data = \"wider_val_v1.npy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Build or load the model\n",
    "### 2.1 Create a new model and load trained Mobinet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T14:33:35.285228Z",
     "start_time": "2018-03-09T22:33:21.379013+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Height, Width, Channels : 512 512 3\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Freezing classification layers\n",
      "\u001b[32mclassification layers freezed\u001b[0m\n",
      "Loading classification weights\n",
      "\u001b[32mClassification weights ./models/ssd_mobilenet_face_epoch_07_loss5.8451.h5 loaded\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 3;\n",
       "            var nbb_formatted_code = \"# 1: Build the Keras model.\\nK.clear_session()  # Clear previous models from memory.\\nmodel, model_layer, img_input, predictor_sizes = mn_model(\\n    image_size=(img_height, img_width, img_channels),\\n    n_classes=n_classes,\\n    min_scale=None,\\n    max_scale=None,\\n    scales=scales,\\n    aspect_ratios_global=None,\\n    aspect_ratios_per_layer=aspect_ratios,\\n    two_boxes_for_ar1=two_boxes_for_ar1,\\n    limit_boxes=limit_boxes,\\n    variances=variances,\\n    coords=coords,\\n    normalize_coords=normalize_coords,\\n)\\n\\n# model.summary()\\n\\nprint(\\\"Freezing classification layers\\\")\\n# Freeze layers\\nfor layer_key in model_layer:\\n    if \\\"detection\\\" not in layer_key:\\n        # prefix detection to freeze layers which does not have detection\\n        model_layer[layer_key].trainable = False\\nprint(colored(\\\"classification layers freezed\\\", \\\"green\\\"))\\n\\n# for layer in model.layers:\\n#   print (colored(layer.name, 'blue'))\\n#   print (colored(layer.trainable, 'green'))\\n\\n# 2: Load some weights into the model.\\nprint(\\\"Loading classification weights\\\")\\n# classification_model = \\\"./base_models/mobilenet_1_0_224_tf.h5\\\"\\nclassification_model = \\\"./models/ssd_mobilenet_face_epoch_07_loss5.8451.h5\\\"\\nmodel.load_weights(classification_model, by_name=True)\\nprint(colored((\\\"Classification weights %s loaded\\\" % classification_model), \\\"green\\\"))\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1: Build the Keras model.\n",
    "K.clear_session()  # Clear previous models from memory.\n",
    "model, model_layer, img_input, predictor_sizes = mn_model(\n",
    "    image_size=(img_height, img_width, img_channels),\n",
    "    n_classes=n_classes,\n",
    "    min_scale=None,\n",
    "    max_scale=None,\n",
    "    scales=scales,\n",
    "    aspect_ratios_global=None,\n",
    "    aspect_ratios_per_layer=aspect_ratios,\n",
    "    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "    limit_boxes=limit_boxes,\n",
    "    variances=variances,\n",
    "    coords=coords,\n",
    "    normalize_coords=normalize_coords,\n",
    ")\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "print(\"Freezing classification layers\")\n",
    "# Freeze layers\n",
    "for layer_key in model_layer:\n",
    "    if \"detection\" not in layer_key:\n",
    "        # prefix detection to freeze layers which does not have detection\n",
    "        model_layer[layer_key].trainable = False\n",
    "print(colored(\"classification layers freezed\", \"green\"))\n",
    "\n",
    "# for layer in model.layers:\n",
    "#   print (colored(layer.name, 'blue'))\n",
    "#   print (colored(layer.trainable, 'green'))\n",
    "\n",
    "# 2: Load some weights into the model.\n",
    "print(\"Loading classification weights\")\n",
    "# classification_model = \"./base_models/mobilenet_1_0_224_tf.h5\"\n",
    "classification_model = \"./models/ssd_mobilenet_face_epoch_07_loss5.8451.h5\"\n",
    "model.load_weights(classification_model, by_name=True)\n",
    "print(colored((\"Classification weights %s loaded\" % classification_model), \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /content/clouderizer/fastai-v1/code/facedetection/ssdsmobinet/keras_loss_function/keras_ssd_loss.py:136: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /content/clouderizer/fastai-v1/code/facedetection/ssdsmobinet/keras_loss_function/keras_ssd_loss.py:180: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 4;\n",
       "            var nbb_formatted_code = \"# 3: Instantiate an optimizer and the SSD loss function and compile the model.\\n# Adam\\nbase_lr = 0.002\\nadam = Adam(lr=base_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-6, decay=0.0)\\nssd_loss = SSDLoss(neg_pos_ratio=2, n_neg_min=0, alpha=1.0)\\nmodel.compile(optimizer=adam, loss=ssd_loss.compute_loss)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3: Instantiate an optimizer and the SSD loss function and compile the model.\n",
    "# Adam\n",
    "base_lr = 0.002\n",
    "adam = Adam(lr=base_lr, beta_1=0.9, beta_2=0.999, epsilon=1e-6, decay=0.0)\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=2, n_neg_min=0, alpha=1.0)\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Load a previously created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 5;\n",
       "            var nbb_formatted_code = \"# # Load a previously model\\n# model_path = './models/ssd_mobilenet_face_epoch_01_loss6.0995.h5'\\n\\n# # We need to create an SSDLoss object in order to pass that to the model loader.\\n# ssd_loss = SSDLoss(neg_pos_ratio=2, alpha=1.0)\\n\\n# K.clear_session() # Clear previous models from memory.\\n\\n# model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\\n#                                                'L2Normalization': L2Normalization,\\n#                                                'compute_loss': ssd_loss.compute_loss})\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Load a previously model\n",
    "# model_path = './models/ssd_mobilenet_face_epoch_01_loss6.0995.h5'\n",
    "\n",
    "# # We need to create an SSDLoss object in order to pass that to the model loader.\n",
    "# ssd_loss = SSDLoss(neg_pos_ratio=2, alpha=1.0)\n",
    "\n",
    "# K.clear_session() # Clear previous models from memory.\n",
    "\n",
    "# model = load_model(model_path, custom_objects={'AnchorBoxes': AnchorBoxes,\n",
    "#                                                'L2Normalization': L2Normalization,\n",
    "#                                                'compute_loss': ssd_loss.compute_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3. Set up the data generators for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 6;\n",
       "            var nbb_formatted_code = \"batch_size = 64\\nnum_epochs = 10\\n# Create ground truth box encoder\\nssd_box_encoder = SSDBoxEncoder(\\n    img_height=img_height,\\n    img_width=img_width,\\n    n_classes=n_classes,\\n    predictor_sizes=predictor_sizes,\\n    min_scale=None,\\n    max_scale=None,\\n    scales=scales,\\n    aspect_ratios_global=None,\\n    aspect_ratios_per_layer=aspect_ratios,\\n    two_boxes_for_ar1=two_boxes_for_ar1,\\n    limit_boxes=limit_boxes,\\n    variances=variances,\\n    pos_iou_threshold=0.5,\\n    neg_iou_threshold=0.2,\\n    coords=coords,\\n    normalize_coords=normalize_coords,\\n)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "# Create ground truth box encoder\n",
    "ssd_box_encoder = SSDBoxEncoder(\n",
    "    img_height=img_height,\n",
    "    img_width=img_width,\n",
    "    n_classes=n_classes,\n",
    "    predictor_sizes=predictor_sizes,\n",
    "    min_scale=None,\n",
    "    max_scale=None,\n",
    "    scales=scales,\n",
    "    aspect_ratios_global=None,\n",
    "    aspect_ratios_per_layer=aspect_ratios,\n",
    "    two_boxes_for_ar1=two_boxes_for_ar1,\n",
    "    limit_boxes=limit_boxes,\n",
    "    variances=variances,\n",
    "    pos_iou_threshold=0.5,\n",
    "    neg_iou_threshold=0.2,\n",
    "    coords=coords,\n",
    "    normalize_coords=normalize_coords,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Total number of training samples = 12620\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 7;\n",
       "            var nbb_formatted_code = \"train_dataset = BatchGenerator(\\n    images_path=train_data,\\n    include_classes=\\\"all\\\",\\n    box_output_format=[\\\"class_id\\\", \\\"xmin\\\", \\\"xmax\\\", \\\"ymin\\\", \\\"ymax\\\"],\\n)\\n\\nprint(\\\"TRAINING DATA\\\")\\n\\ntrain_dataset.parse_xml(\\n    annotations_path=train_data,\\n    image_set_path=path.DRIVE_BASE_PATH,\\n    image_set=\\\"None\\\",\\n    classes=class_names,\\n    exclude_truncated=False,\\n    exclude_difficult=False,\\n    ret=False,\\n    debug=False,\\n)\\n\\ntrain_generator = train_dataset.generate(\\n    batch_size=batch_size,\\n    train=True,\\n    ssd_box_encoder=ssd_box_encoder,\\n    equalize=True,\\n    brightness=(0.5, 2, 0.5),\\n    flip=0.5,\\n    translate=((0, 20), (0, 30), 0.5),\\n    scale=(0.75, 1.2, 0.5),\\n    crop=False,\\n    # random_crop = (img_height,img_width,1,3),\\n    random_crop=False,\\n    resize=(img_height, img_width),\\n    # resize=False,\\n    gray=False,\\n    limit_boxes=True,\\n    include_thresh=0.4,\\n    diagnostics=False,\\n)\\n\\nn_train_samples = train_dataset.get_n_samples()\\n\\nprint(\\\"Total number of training samples = {}\\\".format(n_train_samples))\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = BatchGenerator(\n",
    "    images_path=train_data,\n",
    "    include_classes=\"all\",\n",
    "    box_output_format=[\"class_id\", \"xmin\", \"xmax\", \"ymin\", \"ymax\"],\n",
    ")\n",
    "\n",
    "print(\"TRAINING DATA\")\n",
    "\n",
    "train_dataset.parse_xml(\n",
    "    annotations_path=train_data,\n",
    "    image_set_path=path.DRIVE_BASE_PATH,\n",
    "    image_set=\"None\",\n",
    "    classes=class_names,\n",
    "    exclude_truncated=False,\n",
    "    exclude_difficult=False,\n",
    "    ret=False,\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "train_generator = train_dataset.generate(\n",
    "    batch_size=batch_size,\n",
    "    train=True,\n",
    "    ssd_box_encoder=ssd_box_encoder,\n",
    "    equalize=True,\n",
    "    brightness=(0.5, 2, 0.5),\n",
    "    flip=0.5,\n",
    "    translate=((0, 20), (0, 30), 0.5),\n",
    "    scale=(0.75, 1.2, 0.5),\n",
    "    crop=False,\n",
    "    # random_crop = (img_height,img_width,1,3),\n",
    "    random_crop=False,\n",
    "    resize=(img_height, img_width),\n",
    "    # resize=False,\n",
    "    gray=False,\n",
    "    limit_boxes=True,\n",
    "    include_thresh=0.4,\n",
    "    diagnostics=False,\n",
    ")\n",
    "\n",
    "n_train_samples = train_dataset.get_n_samples()\n",
    "\n",
    "print(\"Total number of training samples = {}\".format(n_train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA\n",
      "Total number of validation samples = 3143\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 8;\n",
       "            var nbb_formatted_code = \"print(\\\"VALIDATION DATA\\\")\\n\\nval_dataset = BatchGenerator(\\n    images_path=test_data,\\n    include_classes=\\\"all\\\",\\n    box_output_format=[\\\"class_id\\\", \\\"xmin\\\", \\\"xmax\\\", \\\"ymin\\\", \\\"ymax\\\"],\\n)\\n\\n\\nval_dataset.parse_xml(\\n    annotations_path=test_data,\\n    image_set_path=path.DRIVE_BASE_PATH,\\n    image_set=\\\"None\\\",\\n    classes=class_names,\\n    exclude_truncated=False,\\n    exclude_difficult=False,\\n    ret=False,\\n    debug=False,\\n)\\n\\n\\nval_generator = val_dataset.generate(\\n    batch_size=batch_size,\\n    train=True,\\n    ssd_box_encoder=ssd_box_encoder,\\n    equalize=False,\\n    brightness=False,\\n    flip=False,\\n    translate=False,\\n    scale=False,\\n    crop=False,\\n    # random_crop = (img_height,img_width,1,3),\\n    random_crop=False,\\n    resize=(img_height, img_width),\\n    # resize=False,\\n    gray=False,\\n    limit_boxes=True,\\n    include_thresh=0.4,\\n    diagnostics=False,\\n)\\n\\nn_val_samples = val_dataset.get_n_samples()\\n\\nprint(\\\"Total number of validation samples = {}\\\".format(n_val_samples))\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"VALIDATION DATA\")\n",
    "\n",
    "val_dataset = BatchGenerator(\n",
    "    images_path=test_data,\n",
    "    include_classes=\"all\",\n",
    "    box_output_format=[\"class_id\", \"xmin\", \"xmax\", \"ymin\", \"ymax\"],\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset.parse_xml(\n",
    "    annotations_path=test_data,\n",
    "    image_set_path=path.DRIVE_BASE_PATH,\n",
    "    image_set=\"None\",\n",
    "    classes=class_names,\n",
    "    exclude_truncated=False,\n",
    "    exclude_difficult=False,\n",
    "    ret=False,\n",
    "    debug=False,\n",
    ")\n",
    "\n",
    "\n",
    "val_generator = val_dataset.generate(\n",
    "    batch_size=batch_size,\n",
    "    train=True,\n",
    "    ssd_box_encoder=ssd_box_encoder,\n",
    "    equalize=False,\n",
    "    brightness=False,\n",
    "    flip=False,\n",
    "    translate=False,\n",
    "    scale=False,\n",
    "    crop=False,\n",
    "    # random_crop = (img_height,img_width,1,3),\n",
    "    random_crop=False,\n",
    "    resize=(img_height, img_width),\n",
    "    # resize=False,\n",
    "    gray=False,\n",
    "    limit_boxes=True,\n",
    "    include_thresh=0.4,\n",
    "    diagnostics=False,\n",
    ")\n",
    "\n",
    "n_val_samples = val_dataset.get_n_samples()\n",
    "\n",
    "print(\"Total number of validation samples = {}\".format(n_val_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4. Set the remaining training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T14:40:49.615390Z",
     "start_time": "2018-03-09T22:36:54.863941+08:00"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 9;\n",
       "            var nbb_formatted_code = \"def scheduler(epoch):\\n    if epoch % 10 == 0 and epoch != 0:\\n        lr = K.get_value(model.optimizer.lr)\\n        K.set_value(model.optimizer.lr, lr * 0.95)\\n        print(\\\"lr changed to {}\\\".format(lr * 0.95))\\n    else:\\n        print(\\\"lr remains {}\\\".format(K.get_value(model.optimizer.lr)))\\n\\n    return K.get_value(model.optimizer.lr)\\n\\n\\n# Define a learning rate schedule.\\nlr_schedule = LearningRateScheduler(scheduler)\\n\\n# Define model callbacks.\\nearly_stopping = EarlyStopping(monitor=\\\"val_loss\\\", min_delta=0.001, patience=100)\\nmodel_checkpoint = ModelCheckpoint(\\n    det_model_path + \\\"ssd_mobilenet_face_epoch_{epoch:02d}_loss{val_loss:.4f}.h5\\\",\\n    monitor=\\\"val_loss\\\",\\n    verbose=1,\\n    save_best_only=True,\\n    save_weights_only=True,\\n    mode=\\\"auto\\\",\\n    period=1,\\n)\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scheduler(epoch):\n",
    "    if epoch % 10 == 0 and epoch != 0:\n",
    "        lr = K.get_value(model.optimizer.lr)\n",
    "        K.set_value(model.optimizer.lr, lr * 0.95)\n",
    "        print(\"lr changed to {}\".format(lr * 0.95))\n",
    "    else:\n",
    "        print(\"lr remains {}\".format(K.get_value(model.optimizer.lr)))\n",
    "\n",
    "    return K.get_value(model.optimizer.lr)\n",
    "\n",
    "\n",
    "# Define a learning rate schedule.\n",
    "lr_schedule = LearningRateScheduler(scheduler)\n",
    "\n",
    "# Define model callbacks.\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=100)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    det_model_path + \"ssd_mobilenet_face_epoch_{epoch:02d}_loss{val_loss:.4f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode=\"auto\",\n",
    "    period=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 10;\n",
       "            var nbb_formatted_code = \"# Now start the training\\n# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\\n# initial_epoch = 7\\n# final_epoch = num_epochs\\n# steps_per_epoch = ceil(n_train_samples / batch_size) * 2\\n\\n# history = model.fit_generator(\\n#     generator=train_generator,\\n#     steps_per_epoch=steps_per_epoch,\\n#     epochs=final_epoch,\\n#     callbacks=[model_checkpoint, lr_schedule, early_stopping],\\n#     validation_data=val_generator,\\n#     validation_steps=ceil(n_val_samples / batch_size),\\n#     initial_epoch=initial_epoch,\\n# )\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now start the training\n",
    "# If you're resuming a previous training, set `initial_epoch` and `final_epoch` accordingly.\n",
    "# initial_epoch = 7\n",
    "# final_epoch = num_epochs\n",
    "# steps_per_epoch = ceil(n_train_samples / batch_size) * 2\n",
    "\n",
    "# history = model.fit_generator(\n",
    "#     generator=train_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     epochs=final_epoch,\n",
    "#     callbacks=[model_checkpoint, lr_schedule, early_stopping],\n",
    "#     validation_data=val_generator,\n",
    "#     validation_steps=ceil(n_val_samples / batch_size),\n",
    "#     initial_epoch=initial_epoch,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 6. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T15:11:52.562338Z",
     "start_time": "2018-03-09T23:11:52.383835+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mweights ./models/ssd_mobilenet_face_epoch_10_loss5.8161.h5 loaded\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        setTimeout(function() {\n",
       "            var nbb_cell_id = 11;\n",
       "            var nbb_formatted_code = \"model_path = \\\"./models/\\\"\\n# model_name = \\\"ssd_mobilenet_face_epoch_25_loss0.0916.h5\\\"\\nmodel_name = \\\"ssd_mobilenet_face_epoch_10_loss5.8161.h5\\\"\\n\\nmodel.load_weights(model_path + model_name, by_name=True)\\n\\nprint(colored(\\\"weights %s loaded\\\" % (model_path + model_name), \\\"green\\\"))\\n\\n\\ndef save_bb(save_path, filename, results, prediction=True):\\n\\n    # print filename\\n\\n    img = image.load_img(filename, target_size=(img_height, img_width))\\n    img = image.img_to_array(img)\\n\\n    filename = filename.split(\\\"/\\\")[-1]\\n\\n    if not prediction:\\n        filename = filename[:-4] + \\\"_gt\\\" + \\\".jpg\\\"\\n\\n    # fig,current_axis = plt.subplots(1)\\n    current_axis = plt.gca()\\n\\n    # Get detections with confidence higher than 0.6.\\n    colors = plt.cm.hsv(np.linspace(0, 1, 25)).tolist()\\n    color_code = min(len(results), 16)\\n    print(colored(\\\"total number of bbs: %d\\\" % len(results), \\\"yellow\\\"))\\n    det_conf = None\\n    for result in results:\\n        # Parse the outputs.\\n\\n        if prediction:\\n            det_label = result[0]\\n            det_conf = result[1]\\n            det_xmin = result[2]\\n            det_xmax = result[3]\\n            det_ymin = result[4]\\n            det_ymax = result[5]\\n        else:\\n            det_label = result[0]\\n            det_xmin = result[1]\\n            det_xmax = result[2]\\n            det_ymin = result[3]\\n            det_ymax = result[4]\\n\\n        xmin = int(det_xmin)\\n        ymin = int(det_ymin)\\n        xmax = int(det_xmax)\\n        ymax = int(det_ymax)\\n\\n        if prediction:\\n            score = det_conf\\n\\n        plt.imshow(img / 255.0)\\n\\n        label = int(int(det_label))\\n        label_name = class_names[label]\\n        # print label_name\\n        # print label\\n\\n        if prediction:\\n            display_txt = \\\"{:0.2f}\\\".format(score)\\n        else:\\n            display_txt = \\\"{}\\\".format(label_name)\\n\\n        # print (xmin, ymin, ymin, ymax)\\n        box_coords = (xmin, ymin), (xmax - xmin), (ymax - ymin)\\n        color_code = color_code - 1\\n        color = colors[color_code]\\n        current_axis.add_patch(\\n            plt.Rectangle(*box_coords, fill=False, edgecolor=color, linewidth=2)\\n        )\\n        current_axis.text(\\n            xmin, ymin, display_txt, bbox={\\\"facecolor\\\": color, \\\"alpha\\\": 0.2}\\n        )\\n\\n    current_axis.axes.get_yaxis().set_visible(False)\\n    current_axis.axes.get_xaxis().set_visible(False)\\n    plt.savefig(save_path + filename, bbox_inches=\\\"tight\\\")\\n\\n    print(\\\"saved\\\", save_path + filename)\\n\\n    plt.clf()\";\n",
       "            var nbb_cells = Jupyter.notebook.get_cells();\n",
       "            for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                    nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                    break;\n",
       "                }\n",
       "            }\n",
       "        }, 500);\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_path = \"./models/\"\n",
    "# model_name = \"ssd_mobilenet_face_epoch_25_loss0.0916.h5\"\n",
    "model_name = \"ssd_mobilenet_face_epoch_10_loss5.8161.h5\"\n",
    "\n",
    "model.load_weights(model_path + model_name, by_name=True)\n",
    "\n",
    "print(colored(\"weights %s loaded\" % (model_path + model_name), \"green\"))\n",
    "\n",
    "\n",
    "def save_bb(save_path, filename, results, prediction=True):\n",
    "\n",
    "    # print filename\n",
    "\n",
    "    img = image.load_img(filename, target_size=(img_height, img_width))\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    filename = filename.split(\"/\")[-1]\n",
    "\n",
    "    if not prediction:\n",
    "        filename = filename[:-4] + \"_gt\" + \".jpg\"\n",
    "\n",
    "    # fig,current_axis = plt.subplots(1)\n",
    "    current_axis = plt.gca()\n",
    "\n",
    "    # Get detections with confidence higher than 0.6.\n",
    "    colors = plt.cm.hsv(np.linspace(0, 1, 25)).tolist()\n",
    "    color_code = min(len(results), 16)\n",
    "    print(colored(\"total number of bbs: %d\" % len(results), \"yellow\"))\n",
    "    det_conf = None\n",
    "    for result in results:\n",
    "        # Parse the outputs.\n",
    "\n",
    "        if prediction:\n",
    "            det_label = result[0]\n",
    "            det_conf = result[1]\n",
    "            det_xmin = result[2]\n",
    "            det_xmax = result[3]\n",
    "            det_ymin = result[4]\n",
    "            det_ymax = result[5]\n",
    "        else:\n",
    "            det_label = result[0]\n",
    "            det_xmin = result[1]\n",
    "            det_xmax = result[2]\n",
    "            det_ymin = result[3]\n",
    "            det_ymax = result[4]\n",
    "\n",
    "        xmin = int(det_xmin)\n",
    "        ymin = int(det_ymin)\n",
    "        xmax = int(det_xmax)\n",
    "        ymax = int(det_ymax)\n",
    "\n",
    "        if prediction:\n",
    "            score = det_conf\n",
    "\n",
    "        plt.imshow(img / 255.0)\n",
    "\n",
    "        label = int(int(det_label))\n",
    "        label_name = class_names[label]\n",
    "        # print label_name\n",
    "        # print label\n",
    "\n",
    "        if prediction:\n",
    "            display_txt = \"{:0.2f}\".format(score)\n",
    "        else:\n",
    "            display_txt = \"{}\".format(label_name)\n",
    "\n",
    "        # print (xmin, ymin, ymin, ymax)\n",
    "        box_coords = (xmin, ymin), (xmax - xmin), (ymax - ymin)\n",
    "        color_code = color_code - 1\n",
    "        color = colors[color_code]\n",
    "        current_axis.add_patch(\n",
    "            plt.Rectangle(*box_coords, fill=False, edgecolor=color, linewidth=2)\n",
    "        )\n",
    "        current_axis.text(\n",
    "            xmin, ymin, display_txt, bbox={\"facecolor\": color, \"alpha\": 0.2}\n",
    "        )\n",
    "\n",
    "    current_axis.axes.get_yaxis().set_visible(False)\n",
    "    current_axis.axes.get_xaxis().set_visible(False)\n",
    "    plt.savefig(save_path + filename, bbox_inches=\"tight\")\n",
    "\n",
    "    print(\"saved\", save_path + filename)\n",
    "\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T15:42:25.277298Z",
     "start_time": "2018-03-09T23:42:06.631484+08:00"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDone.\u001b[0m\n",
      "\u001b[33mNow predicting...\u001b[0m\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/35_Basketball_playingbasketball_35_156.jpg\n",
      "\u001b[33mtotal number of bbs: 3\u001b[0m\n",
      "saved ./output_test/35_Basketball_playingbasketball_35_156_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 5\u001b[0m\n",
      "saved ./output_test/12_Group_Team_Organized_Group_12_Group_Team_Organized_Group_12_274.jpg\n",
      "\u001b[33mtotal number of bbs: 5\u001b[0m\n",
      "saved ./output_test/12_Group_Team_Organized_Group_12_Group_Team_Organized_Group_12_274_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/13_Interview_Interview_2_People_Visible_13_1001.jpg\n",
      "\u001b[33mtotal number of bbs: 3\u001b[0m\n",
      "saved ./output_test/13_Interview_Interview_2_People_Visible_13_1001_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/58_Hockey_icehockey_puck_58_469.jpg\n",
      "\u001b[33mtotal number of bbs: 18\u001b[0m\n",
      "saved ./output_test/58_Hockey_icehockey_puck_58_469_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 3\u001b[0m\n",
      "saved ./output_test/17_Ceremony_Ceremony_17_782.jpg\n",
      "\u001b[33mtotal number of bbs: 2\u001b[0m\n",
      "saved ./output_test/17_Ceremony_Ceremony_17_782_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 5\u001b[0m\n",
      "saved ./output_test/0_Parade_marchingband_1_517.jpg\n",
      "\u001b[33mtotal number of bbs: 7\u001b[0m\n",
      "saved ./output_test/0_Parade_marchingband_1_517_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 3\u001b[0m\n",
      "saved ./output_test/20_Family_Group_Family_Group_20_1015.jpg\n",
      "\u001b[33mtotal number of bbs: 4\u001b[0m\n",
      "saved ./output_test/20_Family_Group_Family_Group_20_1015_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 0\u001b[0m\n",
      "saved ./output_test/25_Soldier_Patrol_Soldier_Patrol_25_9.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/25_Soldier_Patrol_Soldier_Patrol_25_9_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/51_Dresses_wearingdress_51_874.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/51_Dresses_wearingdress_51_874_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/44_Aerobics_Aerobics_44_231.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/44_Aerobics_Aerobics_44_231_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/46_Jockey_Jockey_46_409.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/46_Jockey_Jockey_46_409_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/38_Tennis_Tennis_38_81.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/38_Tennis_Tennis_38_81_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/56_Voter_peoplevoting_56_558.jpg\n",
      "\u001b[33mtotal number of bbs: 3\u001b[0m\n",
      "saved ./output_test/56_Voter_peoplevoting_56_558_gt.jpg\n",
      "\u001b[33mtotal number of bbs: 1\u001b[0m\n",
      "saved ./output_test/26_Soldier_Drilling_Soldiers_Drilling_26_192.jpg\n",
      "\u001b[33mtotal number of bbs: 6\u001b[0m\n",
      "saved ./output_test/26_Soldier_Drilling_Soldiers_Drilling_26_192_gt.jpg\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 1: Set the generator for the predictions.\n",
    "test_size = 16\n",
    "test_generator = val_dataset.generate(\n",
    "    batch_size=test_size,\n",
    "    train=False,\n",
    "    ssd_box_encoder=ssd_box_encoder,\n",
    "    equalize=False,\n",
    "    brightness=False,\n",
    "    flip=False,\n",
    "    translate=False,\n",
    "    scale=False,\n",
    "    crop=False,\n",
    "    random_crop=False,\n",
    "    resize=(img_height, img_width),\n",
    "    gray=False,\n",
    "    limit_boxes=True,\n",
    "    include_thresh=0.4,\n",
    "    diagnostics=False,\n",
    ")\n",
    "\n",
    "print(colored(\"Done.\", \"green\"))\n",
    "\n",
    "print(colored(\"Now predicting...\", \"yellow\"))\n",
    "\n",
    "_CONF = 0.60\n",
    "_IOU = 0.15\n",
    "\n",
    "for i in range(test_size):\n",
    "    X, y, filenames = next(test_generator)\n",
    "    y_pred = model.predict(X)\n",
    "    # 4: Decode the raw predictions in `y_pred`.\n",
    "    y_pred_decoded = decode_y2(\n",
    "        y_pred,\n",
    "        confidence_thresh=_CONF,\n",
    "        iou_threshold=_IOU,\n",
    "        top_k=\"all\",\n",
    "        normalize_coords=normalize_coords,\n",
    "        input_coords=coords,\n",
    "        img_height=img_height,\n",
    "        img_width=img_width,\n",
    "    )\n",
    "\n",
    "    np.set_printoptions(suppress=True)\n",
    "\n",
    "    save_bb(\"./output_test/\", filenames[i], y_pred_decoded[i])\n",
    "    save_bb(\"./output_test/\", filenames[i], y[i], prediction=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}